# üìö MI√âRCOLES 12 NOV - SEMANA 2: Clasificaci√≥n y M√©tricas

**Fecha:** Mi√©rcoles 12 de noviembre 2025  
**Semana:** 2 de 6  
**Tema:** Clasificaci√≥n y m√©tricas de evaluaci√≥n  
**Duraci√≥n:** 1 hora 30 minutos

---

## üéØ Objetivos del d√≠a

Al finalizar hoy deber√°s:

- ‚úÖ Entender qu√© es clasificaci√≥n y en qu√© se diferencia de regresi√≥n
- ‚úÖ Dominar la matriz de confusi√≥n (TP, TN, FP, FN)
- ‚úÖ Comprender las 4 m√©tricas principales: Accuracy, Precision, Recall, F1-Score
- ‚úÖ **Entender ROC Curve y AUC**
- ‚úÖ Saber cu√°ndo priorizar Precision vs Recall
- ‚úÖ Interpretar m√©tricas en contexto real

---

## üìñ PARTE 1: ¬øQu√© es Clasificaci√≥n? (15 minutos)

### Definici√≥n

**Clasificaci√≥n:** Tipo de Machine Learning supervisado donde predices una **categor√≠a** o **clase**.

**Diferencia con Regresi√≥n:**

- **Regresi√≥n:** Predice **n√∫meros** (precio, temperatura, edad)
- **Clasificaci√≥n:** Predice **categor√≠as** (spam/no spam, perro/gato, sano/enfermo)

---

### Tipos de clasificaci√≥n

**1. Clasificaci√≥n Binaria (2 clases)**

- Spam o No spam
- Fraude o Leg√≠timo
- Positivo o Negativo (enfermedad)
- Aprobar o Reprobar

**2. Clasificaci√≥n Multiclase (3+ clases)**

- Tipo de flor (setosa, versicolor, virginica)
- Categor√≠a de producto (electr√≥nica, ropa, hogar)
- Nivel de riesgo (bajo, medio, alto)
- Reconocimiento de d√≠gitos (0-9)

**3. Clasificaci√≥n Multilabel**

- Un √≠tem puede pertenecer a m√∫ltiples clases
- Ejemplo: Una pel√≠cula puede ser "Acci√≥n" Y "Comedia" Y "Sci-Fi"

---

### Ejemplos del mundo real

**Medicina:**

- Diagn√≥stico: ¬øTiene c√°ncer? (s√≠/no)
- Tipo de tumor: benigno, maligno, metast√°sico

**Finanzas:**

- Aprobaci√≥n de cr√©dito: aprobar/rechazar
- Nivel de riesgo: bajo, medio, alto

**Marketing:**

- Probabilidad de compra: comprar√°/no comprar√°
- Segmentaci√≥n de clientes: premium, regular, b√°sico

**Tecnolog√≠a:**

- Filtro de spam: spam/leg√≠timo
- Reconocimiento de voz: 10 d√≠gitos (0-9)
- Moderaci√≥n de contenido: apropiado/inapropiado

---

## üìñ PARTE 2: Matriz de Confusi√≥n (20 minutos)

### ¬øQu√© es?

**La matriz de confusi√≥n** muestra c√≥mo se desempe√±a tu modelo comparando predicciones vs realidad.

**Para clasificaci√≥n binaria:**

```
                    PREDICCI√ìN
                 Negativo  Positivo
                 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
REALIDAD  Neg |     TN        FP
          Pos |     FN        TP
```

---

### Los 4 elementos clave

**1. True Positive (TP) - Verdadero Positivo**

- **Realidad:** Positivo
- **Predicci√≥n:** Positivo
- **Resultado:** ‚úÖ CORRECTO
- **Ejemplo:** Email es spam y el modelo lo detecta como spam

**2. True Negative (TN) - Verdadero Negativo**

- **Realidad:** Negativo
- **Predicci√≥n:** Negativo
- **Resultado:** ‚úÖ CORRECTO
- **Ejemplo:** Email es leg√≠timo y el modelo lo clasifica como leg√≠timo

**3. False Positive (FP) - Falso Positivo**

- **Realidad:** Negativo
- **Predicci√≥n:** Positivo
- **Resultado:** ‚ùå ERROR (Falsa alarma)
- **Ejemplo:** Email es leg√≠timo pero el modelo lo marca como spam
- **Tambi√©n llamado:** Error Tipo I

**4. False Negative (FN) - Falso Negativo**

- **Realidad:** Positivo
- **Predicci√≥n:** Negativo
- **Resultado:** ‚ùå ERROR (Se me escap√≥)
- **Ejemplo:** Email es spam pero pasa como leg√≠timo
- **Tambi√©n llamado:** Error Tipo II

---

### Ejemplo completo: Detector de spam

**Datos:**

```
100 emails en total:
- 60 son leg√≠timos (reales)
- 40 son spam (reales)
```

**Matriz de confusi√≥n:**

```
                    Predicci√≥n
                 Leg√≠timo    Spam
                 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Real  Leg√≠timo      50        10    ‚Üê TN=50, FP=10
      Spam           5        35    ‚Üê FN=5,  TP=35
```

**Interpretaci√≥n:**

- **TP = 35:** Detect√≥ correctamente 35 emails spam
- **TN = 50:** Identific√≥ correctamente 50 emails leg√≠timos
- **FP = 10:** Marc√≥ incorrectamente 10 emails leg√≠timos como spam (¬°problema!)
- **FN = 5:** Dej√≥ pasar 5 emails spam al inbox

---

### Consejos para recordar

**Trucos nemot√©cnicos:**

**True/False** = ¬øLa predicci√≥n fue correcta?

- **True** ‚Üí Acert√© ‚úÖ
- **False** ‚Üí Me equivoqu√© ‚ùå

**Positive/Negative** = ¬øQu√© predije?

- **Positive** ‚Üí Dije "S√ç"
- **Negative** ‚Üí Dije "NO"

**Combinaciones:**

- **True Positive:** Dije S√ç y acert√© ‚úÖ
- **True Negative:** Dije NO y acert√© ‚úÖ
- **False Positive:** Dije S√ç pero me equivoqu√© ‚ùå (falsa alarma)
- **False Negative:** Dije NO pero me equivoqu√© ‚ùå (se me escap√≥)

---

## üìñ PARTE 3: Las 4 M√©tricas Principales (25 minutos)

### 1Ô∏è‚É£ ACCURACY (Exactitud)

**¬øQu√© mide?**
"¬øQu√© porcentaje de predicciones fueron correctas?"

**F√≥rmula:**

```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
Accuracy = Aciertos totales / Total de predicciones
```

**Ejemplo del detector de spam:**

```
Accuracy = (35 + 50) / 100 = 85 / 100 = 0.85 = 85%
```

**Interpretaci√≥n:**
"El modelo acierta el 85% de las veces"

**‚úÖ Ventajas:**

- S√∫per f√°cil de entender
- Intuitivo para explicar
- M√©trica m√°s com√∫n

**‚ö†Ô∏è PROBLEMA GRAVE: Clases desbalanceadas**

**Ejemplo:**

```
1000 transacciones bancarias:
- 950 son leg√≠timas (95%)
- 50 son fraude (5%)

Modelo TONTO que siempre predice "leg√≠timo":
Accuracy = 95% ‚Üê ¬°Parece bueno!

Pero NUNCA detecta fraude ‚Üê ¬°Es in√∫til!
```

**Por eso necesitamos Precision y Recall.**

---

### 2Ô∏è‚É£ PRECISION (Precisi√≥n)

**¬øQu√© mide?**
"De todo lo que dije que era POSITIVO, ¬øcu√°nto realmente lo era?"

**Pregunta clave:** "¬øQu√© tan confiable soy cuando digo S√ç?"

**F√≥rmula:**

```
Precision = TP / (TP + FP)
Precision = Verdaderos positivos / Todos los que dije positivos
```

**Ejemplo del detector de spam:**

```
Predije "SPAM" para 45 emails (TP=35, FP=10)
Precision = 35 / (35 + 10) = 35 / 45 = 0.78 = 78%
```

**Interpretaci√≥n:**
"Cuando digo que es spam, tengo raz√≥n el 78% de las veces"
"22% de las veces bloqueo emails leg√≠timos" ‚Üê ¬°problema!

**üéØ ¬øCu√°ndo es importante ALTA Precision?**

Cuando los **Falsos Positivos son MUY costosos:**

**Ejemplos:**

- **Filtro de spam:** Bloquear email importante como spam (pierdes info cr√≠tica)
- **Condena judicial:** Encarcelar a inocente (injusticia grave)
- **Diagn√≥stico m√©dico:** Decir que tiene c√°ncer cuando no lo tiene (estr√©s innecesario, tratamientos invasivos)
- **Recomendaciones:** Recomendar producto irrelevante (molesta al usuario)

**Estrategia:** "Prefiero ser conservador y solo decir S√ç cuando estoy muy seguro"

---

### 3Ô∏è‚É£ RECALL (Exhaustividad/Sensibilidad)

**¬øQu√© mide?**
"De todos los casos POSITIVOS reales, ¬øcu√°ntos detect√©?"

**Pregunta clave:** "¬øQu√© tan completo soy en encontrar todos los casos positivos?"

**F√≥rmula:**

```
Recall = TP / (TP + FN)
Recall = Verdaderos positivos / Todos los positivos reales
```

**Ejemplo del detector de spam:**

```
Hab√≠a 40 emails spam reales (TP=35, FN=5)
Recall = 35 / (35 + 5) = 35 / 40 = 0.875 = 87.5%
```

**Interpretaci√≥n:**
"Detecto el 87.5% de todos los emails spam"
"Se me escapan el 12.5% de los spam" ‚Üê algunos llegan al inbox

**üéØ ¬øCu√°ndo es importante ALTO Recall?**

Cuando los **Falsos Negativos son MUY peligrosos:**

**Ejemplos:**

- **Detector de c√°ncer:** NO detectar c√°ncer cuando s√≠ existe (paciente no recibe tratamiento ‚Üí fatal)
- **Detector de fraude:** NO detectar fraude real (pierdes dinero)
- **Sistema antivirus:** NO detectar malware (computadora infectada)
- **Detecci√≥n de fallas:** NO detectar falla en motor de avi√≥n (catastr√≥fico)

**Estrategia:** "Prefiero revisar m√°s casos (incluso falsos positivos) con tal de NO perderme ning√∫n caso real"

---

### 4Ô∏è‚É£ F1-SCORE

**¬øQu√© mide?**
"Balance entre Precision y Recall"

**F√≥rmula:**

```
F1-Score = 2 √ó (Precision √ó Recall) / (Precision + Recall)
```

Es la **media arm√≥nica** de Precision y Recall.

**Ejemplo:**

```
Precision = 0.78 (78%)
Recall = 0.875 (87.5%)

F1 = 2 √ó (0.78 √ó 0.875) / (0.78 + 0.875)
F1 = 2 √ó 0.6825 / 1.655
F1 = 1.365 / 1.655
F1 = 0.825 = 82.5%
```

**Interpretaci√≥n:**

- F1 penaliza extremos (solo alta Precision O solo alto Recall)
- Recompensa balance entre ambos
- √ötil cuando necesitas equilibrio

**üéØ ¬øCu√°ndo usar F1-Score?**

- Cuando tanto FP como FN son problem√°ticos
- Clases desbalanceadas
- Necesitas una m√©trica √∫nica que combine Precision y Recall
- No tienes preferencia clara entre Precision vs Recall

**Nota:** F1 siempre est√° entre Precision y Recall (nunca es mayor que ambos).

---

### üìä Tabla comparativa de m√©tricas

| M√©trica       | F√≥rmula       | Pregunta que responde      | Cu√°ndo priorizar     |
| ------------- | ------------- | -------------------------- | -------------------- |
| **Accuracy**  | (TP+TN)/Total | ¬ø% de aciertos totales?    | Clases balanceadas   |
| **Precision** | TP/(TP+FP)    | ¬øConfiable cuando digo S√ç? | FP muy costosos      |
| **Recall**    | TP/(TP+FN)    | ¬øDetecto todos los S√ç?     | FN muy peligrosos    |
| **F1-Score**  | 2√ó(P√óR)/(P+R) | ¬øBalance P y R?            | Necesitas equilibrio |

---

## üìñ PARTE 4: ROC Curve y AUC (20 minutos)

### ¬øQu√© es ROC?

**ROC (Receiver Operating Characteristic) Curve:**

Es una **gr√°fica** que muestra el rendimiento de un clasificador binario en **todos los umbrales posibles**.

**Ejes de la gr√°fica:**

```
True Positive Rate (TPR)
        ‚Üë
   1.0  |     ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚óè
        |   ‚óè‚îÄ‚îÄ‚óè        ‚Üê Curva ROC
   0.8  | ‚óè‚îÄ‚óè            (mejor modelo)
        |‚óè
   0.6  |      ‚ï±  ‚Üê L√≠nea diagonal
        |    ‚ï±     (modelo aleatorio)
   0.4  |  ‚ï±      AUC = 0.5
        |‚ï±
   0.2  |
        |
   0.0  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí
        0.0  0.2  0.4  0.6  0.8  1.0
              False Positive Rate (FPR)
```

**Eje Y - True Positive Rate (TPR):**

- Tambi√©n llamado: **Recall** o **Sensibilidad**
- F√≥rmula: TPR = TP / (TP + FN)
- Pregunta: "¬øQu√© % de positivos reales detecto?"

**Eje X - False Positive Rate (FPR):**

- Opuesto a: **Especificidad** (FPR = 1 - Especificidad)
- F√≥rmula: FPR = FP / (FP + TN)
- Pregunta: "¬øQu√© % de negativos reales marco incorrectamente como positivos?"

---

### ¬øC√≥mo se crea la curva ROC?

**Concepto de umbral:**

La mayor√≠a de clasificadores no dan respuesta binaria directa, sino una **probabilidad** o **score**:

**Ejemplo detector de spam:**

```
Email 1: score = 0.95 ‚Üí Muy probable spam
Email 2: score = 0.78 ‚Üí Probable spam
Email 3: score = 0.45 ‚Üí Incierto
Email 4: score = 0.23 ‚Üí Probable leg√≠timo
Email 5: score = 0.05 ‚Üí Muy probable leg√≠timo
```

**Puedes elegir diferentes umbrales:**

**Umbral = 0.5** (est√°ndar):

```
score > 0.5 ‚Üí SPAM
score ‚â§ 0.5 ‚Üí LEG√çTIMO
```

**Umbral = 0.8** (conservador):

```
score > 0.8 ‚Üí SPAM (m√°s estricto)
score ‚â§ 0.8 ‚Üí LEG√çTIMO
```

- Menos FP (m√°s Precision)
- M√°s FN (menos Recall)

**Umbral = 0.3** (agresivo):

```
score > 0.3 ‚Üí SPAM (m√°s permisivo)
score ‚â§ 0.3 ‚Üí LEG√çTIMO
```

- M√°s FP (menos Precision)
- Menos FN (m√°s Recall)

**La curva ROC** representa todos estos puntos para TODOS los umbrales posibles.

---

### ¬øQu√© es AUC?

**AUC (Area Under the Curve):**

Es el **√°rea bajo la curva ROC**.

**Rango:** 0 a 1

**Interpretaci√≥n:**

| AUC         | Calidad del modelo             |
| ----------- | ------------------------------ |
| **1.0**     | Perfecto (100% separaci√≥n)     |
| **0.9-1.0** | Excelente                      |
| **0.8-0.9** | Muy bueno                      |
| **0.7-0.8** | Bueno                          |
| **0.6-0.7** | Pobre                          |
| **0.5**     | Aleatorio (como lanzar moneda) |
| **<0.5**    | Peor que aleatorio             |

---

### ¬øQu√© significa AUC en t√©rminos pr√°cticos?

**AUC = 0.85 significa:**

"Si tomas un caso positivo aleatorio y un caso negativo aleatorio, el modelo tiene **85% de probabilidad** de darle mayor score al positivo que al negativo"

**Ejemplo visual:**

```
Caso positivo real:  score = 0.8
Caso negativo real:  score = 0.3

Model correcto: 0.8 > 0.3 ‚úÖ

Con AUC = 0.85, esto pasa el 85% de las veces
```

---

### Ventajas de AUC

**‚úÖ Ventajas:**

1. **M√©trica √∫nica** que resume el rendimiento general
2. **No depende del umbral** de clasificaci√≥n
3. **Funciona bien con clases desbalanceadas**
4. **F√°cil de comparar** diferentes modelos
5. **Robusta** a distribuci√≥n de clases

**Comparaci√≥n de modelos:**

```
Modelo A: AUC = 0.92 ‚Üí Mejor
Modelo B: AUC = 0.87 ‚Üí Bueno
Modelo C: AUC = 0.73 ‚Üí Moderado
```

---

### Curva ROC perfecta vs aleatoria

**Modelo perfecto (AUC = 1.0):**

```
TPR
 ‚Üë
1.0|‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   |‚îÇ
   |‚îÇ
   |‚îÇ
   |‚óè
0.0‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí FPR
   0.0        1.0
```

- Va directo a TPR=1.0 con FPR=0
- Separa perfectamente positivos de negativos

**Modelo aleatorio (AUC = 0.5):**

```
TPR
 ‚Üë
1.0|        ‚óè
   |      ‚ï±
   |    ‚ï±
   |  ‚ï±   ‚Üê L√≠nea diagonal
   |‚ï±
0.0‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí FPR
   0.0        1.0
```

- L√≠nea diagonal de 45 grados
- No mejor que adivinar al azar

---

### ROC y AUC en Azure AutoML

**En Azure AutoML:**

Puedes elegir **"AUC weighted"** como **primary metric** para clasificaci√≥n:

```python
automl_config = AutoMLConfig(
    task='classification',
    primary_metric='AUC_weighted',  ‚Üê Para optimizar AUC
    training_data=dataset,
    label_column_name='target'
)
```

**"AUC weighted":**

- Para clasificaci√≥n multiclase
- Calcula AUC para cada clase
- Promedio ponderado por tama√±o de clase

---

### Cu√°ndo usar AUC vs otras m√©tricas

**Usa AUC cuando:**

- ‚úÖ Clases desbalanceadas
- ‚úÖ Costo de FP y FN es similar
- ‚úÖ Quieres m√©trica independiente del umbral
- ‚úÖ Comparar m√∫ltiples modelos

**Usa Precision cuando:**

- ‚úÖ FP muy costosos
- ‚úÖ Necesitas alta confianza en positivos

**Usa Recall cuando:**

- ‚úÖ FN muy peligrosos
- ‚úÖ No puedes perderte casos positivos

**Usa F1 cuando:**

- ‚úÖ Necesitas balance
- ‚úÖ Clases desbalanceadas

---

### Ejemplo completo: Detector m√©dico

**Escenario:** Detectar c√°ncer de mama

**Matriz de confusi√≥n:**

```
                No c√°ncer    C√°ncer
No c√°ncer         850          50
C√°ncer             30          70
```

**M√©tricas calculadas:**

```
Accuracy = (850+70)/1000 = 92%
Precision = 70/(70+50) = 58.3%
Recall = 70/(70+30) = 70%
F1 = 2√ó(0.583√ó0.70)/(0.583+0.70) = 63.6%

TPR = 70/100 = 0.70
FPR = 50/900 = 0.056

AUC = 0.89 (calculado considerando todos los umbrales)
```

**Interpretaci√≥n:**

- **Alta Accuracy (92%)** pero enga√±osa (clases desbalanceadas)
- **Recall moderado (70%)** - detecta 70% de c√°nceres ‚ö†Ô∏è
- **Precision baja (58.3%)** - muchos falsos positivos
- **AUC bueno (0.89)** - modelo tiene buena capacidad de discriminaci√≥n

**Decisi√≥n:**
Para c√°ncer, **priorizar Recall** (no podemos perdernos casos reales). Ajustar umbral para aumentar Recall, aunque aumente FP.

---

## üìñ PARTE 5: Trade-off Precision vs Recall (10 minutos)

### El dilema fundamental

**NO puedes maximizar ambos simult√°neamente** ‚ö†Ô∏è

```
          Alta Precision
               ‚Üë
               ‚îÇ
   Conservador ‚îÇ
   (digo S√ç solo‚îÇ
    si estoy    ‚îÇ
    muy seguro) ‚îÇ
               ‚îÇ
               ‚îÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Alto Recall
               ‚îÇ
               ‚îÇ Agresivo
               ‚îÇ (digo S√ç con
               ‚îÇ  poca evidencia)
               ‚îÇ
               ‚Üì
         Baja Precision
```

---

### ¬øPor qu√© existe este trade-off?

**Ejemplo detector de spam:**

**Modelo conservador (alta Precision):**

```
Umbral alto = 0.9
Solo marca spam si score > 0.9

Resultado:
‚úÖ Precision alta (pocos FP)
‚ùå Recall bajo (muchos FN - spam no detectado)
```

**Modelo agresivo (alto Recall):**

```
Umbral bajo = 0.3
Marca spam si score > 0.3

Resultado:
‚úÖ Recall alto (pocos FN)
‚ùå Precision baja (muchos FP - emails leg√≠timos bloqueados)
```

---

### ¬øC√≥mo decidir?

**Preg√∫ntate:** "¬øQu√© error es M√ÅS costoso?"

**Tabla de decisi√≥n:**

| Escenario              | FP m√°s costoso                    | FN m√°s costoso        | Priorizar     |
| ---------------------- | --------------------------------- | --------------------- | ------------- |
| Spam email             | Email importante bloqueado        | Spam en inbox         | **Precision** |
| Detector c√°ncer        | Estr√©s por falso positivo         | No tratar c√°ncer real | **Recall**    |
| Fraude bancario        | Bloquear transacci√≥n leg√≠tima     | Perder dinero         | **Recall**    |
| Recomendaci√≥n producto | Molestar con producto irrelevante | Perder venta          | **Precision** |
| Antivirus              | Bloquear programa leg√≠timo        | Infectar computadora  | **Recall**    |

---

## ‚úÖ EJERCICIOS PR√ÅCTICOS (20 minutos)

### Ejercicio 1: Calcular m√©tricas

**Detector de productos defectuosos en f√°brica:**

```
Matriz de confusi√≥n:
                Bueno    Defectuoso
Bueno            850         50
Defectuoso        20         80
```

**Calcula:**

1. Accuracy
2. Precision
3. Recall
4. F1-Score

<details>
<summary>Ver soluci√≥n</summary>

**Identificar valores:**

- TP = 80 (defectuoso detectado correctamente)
- TN = 850 (bueno detectado correctamente)
- FP = 50 (falsa alarma - bueno marcado como defectuoso)
- FN = 20 (error - defectuoso no detectado)
- Total = 1000

**C√°lculos:**

1. **Accuracy:**

```
Accuracy = (TP + TN) / Total
Accuracy = (80 + 850) / 1000
Accuracy = 930 / 1000 = 0.93 = 93%
```

2. **Precision:**

```
Precision = TP / (TP + FP)
Precision = 80 / (80 + 50)
Precision = 80 / 130 = 0.615 = 61.5%
```

3. **Recall:**

```
Recall = TP / (TP + FN)
Recall = 80 / (80 + 20)
Recall = 80 / 100 = 0.80 = 80%
```

4. **F1-Score:**

```
F1 = 2 √ó (Precision √ó Recall) / (Precision + Recall)
F1 = 2 √ó (0.615 √ó 0.80) / (0.615 + 0.80)
F1 = 2 √ó 0.492 / 1.415
F1 = 0.984 / 1.415 = 0.695 = 69.5%
```

**Interpretaci√≥n:**

- Alta Accuracy (93%) - parece bueno
- Precision moderada (61.5%) - muchos falsos positivos (descartar productos buenos)
- Recall bueno (80%) - detecta la mayor√≠a de defectos
- F1 moderado (69.5%) - balance entre P y R

**Problema:** Estamos descartando muchos productos buenos (FP=50). Esto tiene costo econ√≥mico.

</details>

---

### Ejercicio 2: Interpretar escenarios

**Escenario A: Sistema de seguridad aeropuerto**

```
Detector de armas:
Precision = 85%
Recall = 60%
```

**Pregunta:** ¬øEs aceptable? ¬øQu√© m√©trica mejorar√≠as?

<details>
<summary>Ver soluci√≥n</summary>

**‚ùå NO es aceptable**

**Problema:** Recall de 60% significa que el 40% de las armas reales NO se detectan. ¬°Inaceptable en seguridad!

**Soluci√≥n:** **Priorizar Recall** - debemos detectar TODAS las armas, aunque tengamos m√°s falsas alarmas (revisiones manuales extra).

**Trade-off:** Aceptar baja Precision (m√°s revisiones manuales) para maximizar Recall (seguridad).

</details>

---

**Escenario B: Sistema de recomendaci√≥n de pel√≠culas**

```
Precision = 70%
Recall = 40%
```

**Pregunta:** ¬øQu√© m√©trica es m√°s importante aqu√≠?

<details>
<summary>Ver soluci√≥n</summary>

**Priorizar: Precision**

**Raz√≥n:**

- **FP:** Recomendar pel√≠cula mala ‚Üí usuario molesto, pierde confianza
- **FN:** No recomendar pel√≠cula buena ‚Üí hay muchas otras pel√≠culas

Es mejor recomendar pocas pel√≠culas pero muy relevantes (alta Precision) que recomendar muchas incluyendo malas (bajo Precision).

El usuario no puede ver todas las pel√≠culas buenas de todas formas (FN es menos grave).

</details>

---

### Ejercicio 3: Matriz de confusi√≥n multiclase

**Clasificador de flores (3 clases):**

```
              Setosa  Versicolor  Virginica
Setosa          45        3          2
Versicolor       1       38          6
Virginica        0        4         46
```

**Calcula:**

1. Accuracy total
2. Precision para cada clase
3. Recall para cada clase

<details>
<summary>Ver soluci√≥n</summary>

**Total de muestras:** 45+3+2+1+38+6+0+4+46 = 145

**1. Accuracy total:**

```
Predicciones correctas = 45 + 38 + 46 = 129
Accuracy = 129 / 145 = 0.890 = 89%
```

**2. Precision por clase:**

**Setosa:**

```
TP = 45
FP = 1 + 0 = 1
Precision = 45 / (45 + 1) = 45/46 = 0.978 = 97.8%
```

**Versicolor:**

```
TP = 38
FP = 3 + 4 = 7
Precision = 38 / (38 + 7) = 38/45 = 0.844 = 84.4%
```

**Virginica:**

```
TP = 46
FP = 2 + 6 = 8
Precision = 46 / (46 + 8) = 46/54 = 0.852 = 85.2%
```

**3. Recall por clase:**

**Setosa:**

```
TP = 45
FN = 3 + 2 = 5
Recall = 45 / (45 + 5) = 45/50 = 0.90 = 90%
```

**Versicolor:**

```
TP = 38
FN = 1 + 4 = 5
Recall = 38 / (38 + 5) = 38/43 = 0.884 = 88.4%
```

**Virginica:**

```
TP = 46
FN = 6 + 0 = 6
Recall = 46 / (46 + 6) = 46/52 = 0.885 = 88.5%
```

**Interpretaci√≥n:**

- Setosa es la m√°s f√°cil de identificar (alta Precision)
- Las tres clases tienen Recall similar (~88-90%)
- Versicolor y Virginica se confunden m√°s entre s√≠
</details>

---

## üìù FLASHCARDS para crear HOY

### Conceptos b√°sicos

**Tarjeta 1:**

- Frente: "¬øQu√© predice Clasificaci√≥n?"
- Atr√°s: "Categor√≠as o clases (spam/no spam, perro/gato), NO n√∫meros"

**Tarjeta 2:**

- Frente: "Diferencia Clasificaci√≥n vs Regresi√≥n"
- Atr√°s: "Clasificaci√≥n ‚Üí categor√≠as. Regresi√≥n ‚Üí n√∫meros continuos"

**Tarjeta 3:**

- Frente: "True Positive (TP)"
- Atr√°s: "Realidad: Positivo. Predicci√≥n: Positivo. ‚úÖ CORRECTO"

**Tarjeta 4:**

- Frente: "False Positive (FP)"
- Atr√°s: "Realidad: Negativo. Predicci√≥n: Positivo. ‚ùå Falsa alarma"

**Tarjeta 5:**

- Frente: "False Negative (FN)"
- Atr√°s: "Realidad: Positivo. Predicci√≥n: Negativo. ‚ùå Se me escap√≥"

### M√©tricas

**Tarjeta 6:**

- Frente: "F√≥rmula Accuracy"
- Atr√°s: "(TP + TN) / Total. % de predicciones correctas"

**Tarjeta 7:**

- Frente: "F√≥rmula Precision"
- Atr√°s: "TP / (TP + FP). ¬øConfiable cuando digo S√ç?"

**Tarjeta 8:**

- Frente: "F√≥rmula Recall"
- Atr√°s: "TP / (TP + FN). ¬øDetecto todos los S√ç reales?"

**Tarjeta 9:**

- Frente: "F√≥rmula F1-Score"
- Atr√°s: "2 √ó (Precision √ó Recall) / (Precision + Recall). Balance entre P y R"

### ROC y AUC

**Tarjeta 10:**

- Frente: "¬øQu√© es ROC Curve?"
- Atr√°s: "Gr√°fica de TPR (Recall) vs FPR en todos los umbrales posibles"

**Tarjeta 11:**

- Frente: "¬øQu√© es AUC?"
- Atr√°s: "√Årea bajo la curva ROC. Rango: 0-1. Mide capacidad de discriminaci√≥n del modelo"

**Tarjeta 12:**

- Frente: "Interpretaci√≥n AUC = 0.85"
- Atr√°s: "85% probabilidad de que el modelo d√© mayor score a caso positivo que negativo. Modelo muy bueno"

**Tarjeta 13:**

- Frente: "AUC = 0.5 significa..."
- Atr√°s: "Modelo aleatorio, no mejor que lanzar una moneda"

**Tarjeta 14:**

- Frente: "Ventaja de AUC sobre Accuracy"
- Atr√°s: "No depende del umbral, funciona bien con clases desbalanceadas"

### Cu√°ndo usar cada m√©trica

**Tarjeta 15:**

- Frente: "¬øCu√°ndo priorizar Precision?"
- Atr√°s: "Cuando Falsos Positivos son muy costosos (ej: spam, condena judicial)"

**Tarjeta 16:**

- Frente: "¬øCu√°ndo priorizar Recall?"
- Atr√°s: "Cuando Falsos Negativos son muy peligrosos (ej: c√°ncer, fraude, antivirus)"

**Tarjeta 17:**

- Frente: "Trade-off Precision vs Recall"
- Atr√°s: "No puedes maximizar ambos simult√°neamente. Aumentar uno reduce el otro"

**Tarjeta 18:**

- Frente: "Ejemplo FP peligroso"
- Atr√°s: "Detector de spam marca email importante como spam ‚Üí pierdes info cr√≠tica"

**Tarjeta 19:**

- Frente: "Ejemplo FN peligroso"
- Atr√°s: "Detector m√©dico dice 'no hay c√°ncer' pero s√≠ lo hay ‚Üí paciente no recibe tratamiento"

**Tarjeta 20:**

- Frente: "¬øCu√°ndo usar AUC?"
- Atr√°s: "Clases desbalanceadas, comparar modelos, cuando necesitas m√©trica independiente del umbral"

---

## üéØ RESUMEN DEL D√çA

### Lo que aprendiste hoy:

‚úÖ **Clasificaci√≥n vs Regresi√≥n**

- Clasificaci√≥n predice categor√≠as
- Regresi√≥n predice n√∫meros

‚úÖ **Matriz de confusi√≥n**

- TP, TN, FP, FN
- C√≥mo identificar cada uno

‚úÖ **4 m√©tricas principales**

- Accuracy: % aciertos totales
- Precision: confiable cuando digo S√ç
- Recall: detecto todos los S√ç reales
- F1: balance entre P y R

‚úÖ **ROC Curve y AUC**

- ROC: gr√°fica TPR vs FPR
- AUC: √°rea bajo curva (0-1)
- Interpretaci√≥n de AUC
- Ventajas sobre otras m√©tricas

‚úÖ **Trade-off Precision vs Recall**

- No puedes maximizar ambos
- Depende del costo de FP vs FN
- C√≥mo decidir cu√°l priorizar

‚úÖ **Aplicaci√≥n pr√°ctica**

- Detector spam: priorizar Precision
- Detector c√°ncer: priorizar Recall
- Productos defectuosos: depende del costo

---

## üìä Tu progreso en Semana 2

```
Semana 2: Machine Learning en profundidad
‚îú‚îÄ‚îÄ ‚úÖ Lunes 10: Tipos de ML profundo
‚îú‚îÄ‚îÄ ‚úÖ Martes 11: Regresi√≥n y m√©tricas
‚îú‚îÄ‚îÄ ‚úÖ Mi√©rcoles 12: Clasificaci√≥n y m√©tricas (HOY - ACTUALIZADO)
‚îú‚îÄ‚îÄ üìÖ Jueves 13: Azure ML workspace
‚îú‚îÄ‚îÄ üìÖ Viernes 14: AutoML
‚îî‚îÄ‚îÄ üìÖ S√°bado 15: Lab - Crear primer modelo
```

**¬°Ya completaste el 43% de la Semana 2!** üéâ

---

## üìÖ MA√ëANA (Jueves 13 de noviembre)

**Tema:** Azure Machine Learning Workspace en detalle

**Lo que aprender√°s:**

- Qu√© es Azure ML workspace
- Componentes principales (compute, datastores, datasets)
- Azure ML Designer (herramienta visual)
- C√≥mo desplegar modelos
- Diferencia entre Azure ML y otros servicios

---

## üí° CONSEJOS PARA HOY

1. **Practica con los ejercicios** - no solo leas
2. **Crea las flashcards inmediatamente** despu√©s de cada secci√≥n
3. **Relaciona con el Martes:**
   - Martes: m√©tricas para n√∫meros (MAE, RMSE, R¬≤)
   - Mi√©rcoles: m√©tricas para categor√≠as (Accuracy, Precision, Recall, AUC)
4. **Piensa en ejemplos reales** de tu vida/trabajo
5. **La secci√≥n de ROC y AUC** es nueva y importante - rep√°sala bien

---

## üéì PARA EL EXAMEN - PREGUNTAS T√çPICAS

**Ejemplo 1:**
_"Un modelo de detecci√≥n de fraude tiene 95% de Accuracy pero solo detecta el 30% de los fraudes reales. ¬øCu√°l es el problema?"_

- **Respuesta:** Bajo Recall (solo 30%). El modelo tiene alta Accuracy porque la mayor√≠a son transacciones leg√≠timas, pero se pierde el 70% de los fraudes (Falsos Negativos).

**Ejemplo 2:**
_"¬øQu√© m√©trica priorizar√≠as en un sistema que detecta defectos cr√≠ticos en piezas de avi√≥n?"_

- **Respuesta:** Recall - no podemos permitirnos perder ning√∫n defecto cr√≠tico (Falsos Negativos son peligrosos).

**Ejemplo 3:**
_"Tu modelo tiene Precision=90% y Recall=50%. ¬øQu√© significa?"_

- **Respuesta:** El modelo es muy confiable cuando predice positivo (90%), pero se pierde la mitad de los casos positivos reales (50%).

**Ejemplo 4:**
_"¬øQu√© representa el √°rea bajo la curva ROC (AUC)?"_

- **Respuesta:** La capacidad del modelo para discriminar entre clases. AUC=0.85 significa 85% de probabilidad de que el modelo d√© mayor score a un caso positivo que a uno negativo.

**Ejemplo 5:**
_"Un modelo tiene AUC=0.92. ¬øEs un buen modelo?"_

- **Respuesta:** S√≠, es un modelo excelente (0.9-1.0 es rango excelente). Tiene muy buena capacidad de separar clases positivas y negativas.

**Ejemplo 6:**
_"¬øPor qu√© AUC es mejor que Accuracy para clases desbalanceadas?"_

- **Respuesta:** Accuracy puede ser enga√±osa con clases desbalanceadas (un modelo que siempre predice la clase mayoritaria puede tener alta Accuracy pero ser in√∫til). AUC eval√∫a la capacidad de discriminaci√≥n independientemente del desbalanceo.

---

## ‚úÖ CHECKLIST DE HOY

Antes de terminar, aseg√∫rate de:

- [-] Entender clasificaci√≥n vs regresi√≥n
- [-] Dominar matriz de confusi√≥n (TP, TN, FP, FN)
- [-] Saber calcular las 4 m√©tricas principales
- [-] **Entender qu√© son ROC y AUC**
- [-] **Saber cu√°ndo usar AUC vs otras m√©tricas**
- [-] Comprender trade-off Precision vs Recall
- [-] Completar los 3 ejercicios
- [-] Crear las 20 flashcards en Anki
- [-] Repasar flashcards de Lunes y Martes

---

## üöÄ MOTIVACI√ìN

**¬°Excelente progreso!** Clasificaci√≥n y sus m√©tricas son conceptos **fundamentales** en ML.

**Lo que dominas ahora:**

- ‚úÖ Tipos de ML
- ‚úÖ Regresi√≥n completa
- ‚úÖ Clasificaci√≥n completa
- ‚úÖ **ROC y AUC** (concepto avanzado)

## **Ma√±ana:** Conectar√°s todo esto con Azure ML - ver√°s estas m√©tricas en acci√≥n.

**¬°Que tengas un excelente estudio!** üìöüíª

**Nos vemos ma√±ana para Azure ML Workspace.** üöÄ

---

_√öltima actualizaci√≥n: Mi√©rcoles 12 de noviembre 2025_  
_Semana 2 de 6 - D√≠a 3 de 7_
